{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stdlib imports\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "from typing import List, Tuple\n",
    "import traceback\n",
    "\n",
    "# library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# local imports\n",
    "from src.agent.rollout import evaluate, transform_dataset\n",
    "from src.util.dataset_loader import load_datasets\n",
    "from src.util.experiment import Experiment, load_savepoint\n",
    "from src.util.score import evaluate as ev_function\n",
    "from src.transformations import real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "PARAMETER_PATH = os.getenv(\"PARAMETER_PATH\")\n",
    "EXPERIMENT_PATH = os.getenv(\"EXPERIMENT_PATH\")\n",
    "DATA_PATH = os.getenv(\"DATA_PATH\")\n",
    "VALIDATION_DATA_PATH = os.getenv(\"VALIDATION_DATA_PATH\")\n",
    "\n",
    "# Set defaults\n",
    "if PARAMETER_PATH == None: PARAMETER_PATH = \"/home/tobias/ma/test/parameters\"\n",
    "if EXPERIMENT_PATH == None: EXPERIMENT_PATH = \"/home/tobias/ma/test/experiments\"\n",
    "if DATA_PATH == None: DATA_PATH = \"/home/tobias/ma/data\"\n",
    "if VALIDATION_DATA_PATH == None: VALIDATION_DATA_PATH = \"/home/tobias/ma/data/validation\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = real.all_transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rows(params, columns) -> List[Tuple[str]]: \n",
    "\n",
    "    \n",
    "    model_path = os.path.join(EXPERIMENT_PATH, params[\"name\"])\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        print[f\"[ERROR] Path ''{model_path}' does not exist.'\"]\n",
    "    \n",
    "    \n",
    "    f = [x[:-3] for x in next(os.walk(model_path))[2] if x.endswith(\".sd\")]\n",
    "    f = [x for x in f if \"step\" in x]\n",
    "    model_sd_files = [x + \".sd\" for x in f]\n",
    "    model_json_files = [x + \".json\" for x  in f]\n",
    "   \n",
    "    #  Load shared\n",
    "    x = [params[x] for x in columns]\n",
    "    x.append(model_path)\n",
    "    \n",
    "    x.append(params[\"policy_parameters\"][\"enable_local_context\"])\n",
    "    x.append(params[\"policy_parameters\"][\"enable_domain_information\"])\n",
    "    \n",
    "    \n",
    "    # Load train step specific\n",
    "    res = []\n",
    "    for model_file, json_file in zip(model_sd_files, model_json_files):\n",
    "        assert model_file[:-3] == json_file[:-5], f\"{model_file} != {json_file}\"\n",
    "        y = x.copy()\n",
    "        y.append(model_file)\n",
    "    \n",
    "        # TODO here\n",
    "        json_file = os.path.join(model_path, json_file)\n",
    "        json_file = json.load(open(json_file, mode='r'))\n",
    "\n",
    "        \n",
    "        \n",
    "        train_performance = json_file[\"train_performance\"]\n",
    "        test_performance = json_file[\"test_performance\"]\n",
    "        \n",
    "        y.append(train_performance)\n",
    "        y.append(test_performance)\n",
    "        \n",
    "        res.append(y)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found 14 parameter files in '/home/tobias/ma/test/parameters'.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameter_name</th>\n",
       "      <th>learning_algorithm</th>\n",
       "      <th>reward_function</th>\n",
       "      <th>representation_generator</th>\n",
       "      <th>model_path</th>\n",
       "      <th>enable_local_context</th>\n",
       "      <th>enable_domain_information</th>\n",
       "      <th>model_file</th>\n",
       "      <th>train_performance</th>\n",
       "      <th>test_performance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>params_004</td>\n",
       "      <td>REINFORCE</td>\n",
       "      <td>binary_reward</td>\n",
       "      <td>quantile_data_sketch</td>\n",
       "      <td>/home/tobias/ma/test/experiments/params_004</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-2795312369091581638step_0025.sd</td>\n",
       "      <td>-0.026787</td>\n",
       "      <td>0.002246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>params_005</td>\n",
       "      <td>REINFORCE</td>\n",
       "      <td>binary_reward</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>/home/tobias/ma/test/experiments/params_005</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-3204051483301470282step_0050.sd</td>\n",
       "      <td>-0.015515</td>\n",
       "      <td>0.006007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>params_005_01</td>\n",
       "      <td>REINFORCE</td>\n",
       "      <td>binary_reward</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>/home/tobias/ma/test/experiments/params_005_01</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-8764017441242044382step_0000.sd</td>\n",
       "      <td>-0.007299</td>\n",
       "      <td>0.004947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>params_006</td>\n",
       "      <td>REINFORCE</td>\n",
       "      <td>staggered_reward</td>\n",
       "      <td>quantile_data_sketch</td>\n",
       "      <td>/home/tobias/ma/test/experiments/params_006</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4186393700938150504step_0000.sd</td>\n",
       "      <td>-0.006822</td>\n",
       "      <td>0.019954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>params_005</td>\n",
       "      <td>REINFORCE</td>\n",
       "      <td>binary_reward</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>/home/tobias/ma/test/experiments/params_005</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-3204051483301470282step_0125.sd</td>\n",
       "      <td>-0.002613</td>\n",
       "      <td>0.007962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>params_004</td>\n",
       "      <td>REINFORCE</td>\n",
       "      <td>binary_reward</td>\n",
       "      <td>quantile_data_sketch</td>\n",
       "      <td>/home/tobias/ma/test/experiments/params_004</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-2795312369091581638step_0250.sd</td>\n",
       "      <td>0.027599</td>\n",
       "      <td>0.001565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>params_005</td>\n",
       "      <td>REINFORCE</td>\n",
       "      <td>binary_reward</td>\n",
       "      <td>random_sampling</td>\n",
       "      <td>/home/tobias/ma/test/experiments/params_005</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-3204051483301470282step_0225.sd</td>\n",
       "      <td>0.029027</td>\n",
       "      <td>0.013610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>params_004</td>\n",
       "      <td>REINFORCE</td>\n",
       "      <td>binary_reward</td>\n",
       "      <td>quantile_data_sketch</td>\n",
       "      <td>/home/tobias/ma/test/experiments/params_004</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-2795312369091581638step_0375.sd</td>\n",
       "      <td>0.030385</td>\n",
       "      <td>0.006081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>params_004</td>\n",
       "      <td>REINFORCE</td>\n",
       "      <td>binary_reward</td>\n",
       "      <td>quantile_data_sketch</td>\n",
       "      <td>/home/tobias/ma/test/experiments/params_004</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-2795312369091581638step_0400.sd</td>\n",
       "      <td>0.031416</td>\n",
       "      <td>0.001708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>params_004</td>\n",
       "      <td>REINFORCE</td>\n",
       "      <td>binary_reward</td>\n",
       "      <td>quantile_data_sketch</td>\n",
       "      <td>/home/tobias/ma/test/experiments/params_004</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-2795312369091581638step_0300.sd</td>\n",
       "      <td>0.032873</td>\n",
       "      <td>0.004743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    parameter_name learning_algorithm   reward_function  \\\n",
       "42      params_004          REINFORCE     binary_reward   \n",
       "98      params_005          REINFORCE     binary_reward   \n",
       "164  params_005_01          REINFORCE     binary_reward   \n",
       "70      params_006          REINFORCE  staggered_reward   \n",
       "87      params_005          REINFORCE     binary_reward   \n",
       "..             ...                ...               ...   \n",
       "59      params_004          REINFORCE     binary_reward   \n",
       "88      params_005          REINFORCE     binary_reward   \n",
       "52      params_004          REINFORCE     binary_reward   \n",
       "53      params_004          REINFORCE     binary_reward   \n",
       "54      params_004          REINFORCE     binary_reward   \n",
       "\n",
       "    representation_generator                                      model_path  \\\n",
       "42      quantile_data_sketch     /home/tobias/ma/test/experiments/params_004   \n",
       "98           random_sampling     /home/tobias/ma/test/experiments/params_005   \n",
       "164          random_sampling  /home/tobias/ma/test/experiments/params_005_01   \n",
       "70      quantile_data_sketch     /home/tobias/ma/test/experiments/params_006   \n",
       "87           random_sampling     /home/tobias/ma/test/experiments/params_005   \n",
       "..                       ...                                             ...   \n",
       "59      quantile_data_sketch     /home/tobias/ma/test/experiments/params_004   \n",
       "88           random_sampling     /home/tobias/ma/test/experiments/params_005   \n",
       "52      quantile_data_sketch     /home/tobias/ma/test/experiments/params_004   \n",
       "53      quantile_data_sketch     /home/tobias/ma/test/experiments/params_004   \n",
       "54      quantile_data_sketch     /home/tobias/ma/test/experiments/params_004   \n",
       "\n",
       "     enable_local_context  enable_domain_information  \\\n",
       "42                  False                      False   \n",
       "98                  False                      False   \n",
       "164                  True                      False   \n",
       "70                  False                      False   \n",
       "87                  False                      False   \n",
       "..                    ...                        ...   \n",
       "59                  False                      False   \n",
       "88                  False                      False   \n",
       "52                  False                      False   \n",
       "53                  False                      False   \n",
       "54                  False                      False   \n",
       "\n",
       "                           model_file  train_performance  test_performance  \n",
       "42   -2795312369091581638step_0025.sd          -0.026787          0.002246  \n",
       "98   -3204051483301470282step_0050.sd          -0.015515          0.006007  \n",
       "164  -8764017441242044382step_0000.sd          -0.007299          0.004947  \n",
       "70    4186393700938150504step_0000.sd          -0.006822          0.019954  \n",
       "87   -3204051483301470282step_0125.sd          -0.002613          0.007962  \n",
       "..                                ...                ...               ...  \n",
       "59   -2795312369091581638step_0250.sd           0.027599          0.001565  \n",
       "88   -3204051483301470282step_0225.sd           0.029027          0.013610  \n",
       "52   -2795312369091581638step_0375.sd           0.030385          0.006081  \n",
       "53   -2795312369091581638step_0400.sd           0.031416          0.001708  \n",
       "54   -2795312369091581638step_0300.sd           0.032873          0.004743  \n",
       "\n",
       "[204 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all sets of parameters\n",
    "parameter_files = next(os.walk(PARAMETER_PATH))[2]\n",
    "parameter_files = [x for x in parameter_files if x.endswith(\".json\")]\n",
    "\n",
    "print(f\"[INFO] Found {len(parameter_files)} parameter files in '{PARAMETER_PATH}'.\")\n",
    "print()\n",
    "\n",
    "parameter_sets = [json.load(open(os.path.join(PARAMETER_PATH, x), mode='r')) for x in parameter_files]\n",
    "\n",
    "columns = [\"name\", \"learning_algorithm\", \"reward_function\",  \"representation_generator\"]\n",
    "\n",
    "rows = []\n",
    "for p in parameter_sets:\n",
    "    rows.extend(get_rows(p, columns))\n",
    "\n",
    "# Update columns\n",
    "columns.extend([\"model_path\",\"enable_local_context\", \"enable_domain_information\", \"model_file\", \"train_performance\", \"test_performance\"])\n",
    "columns[0] = \"parameter_name\"\n",
    "    \n",
    "masterframe = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "masterframe.sort_values(\"train_performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "params_007       21\n",
       "params_003_10    21\n",
       "params_004       21\n",
       "params_003_11    21\n",
       "params_001       21\n",
       "params_006       20\n",
       "params_003       20\n",
       "params_005       19\n",
       "params_000       19\n",
       "params_002       19\n",
       "params_005_01     1\n",
       "params_003_01     1\n",
       "Name: parameter_name, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masterframe[\"parameter_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameter_name</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>params_000</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.018923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>params_001</td>\n",
       "      <td>0.019896</td>\n",
       "      <td>0.024472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>params_002</td>\n",
       "      <td>0.016909</td>\n",
       "      <td>0.029514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>params_003</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.009736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>params_003_01</td>\n",
       "      <td>-0.003713</td>\n",
       "      <td>-0.003713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>params_003_10</td>\n",
       "      <td>0.006144</td>\n",
       "      <td>0.016859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>params_003_11</td>\n",
       "      <td>0.016756</td>\n",
       "      <td>0.024442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>params_004</td>\n",
       "      <td>0.003860</td>\n",
       "      <td>0.007718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>params_005</td>\n",
       "      <td>0.010905</td>\n",
       "      <td>0.015994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>params_005_01</td>\n",
       "      <td>0.004947</td>\n",
       "      <td>0.004947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>params_006</td>\n",
       "      <td>0.010215</td>\n",
       "      <td>0.025120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>params_007</td>\n",
       "      <td>0.003207</td>\n",
       "      <td>0.006633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parameter_name      mean       max\n",
       "0      params_000  0.008986  0.018923\n",
       "1      params_001  0.019896  0.024472\n",
       "2      params_002  0.016909  0.029514\n",
       "3      params_003  0.006373  0.009736\n",
       "4   params_003_01 -0.003713 -0.003713\n",
       "5   params_003_10  0.006144  0.016859\n",
       "6   params_003_11  0.016756  0.024442\n",
       "7      params_004  0.003860  0.007718\n",
       "8      params_005  0.010905  0.015994\n",
       "9   params_005_01  0.004947  0.004947\n",
       "10     params_006  0.010215  0.025120\n",
       "11     params_007  0.003207  0.006633"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = masterframe[[\"parameter_name\", \"test_performance\"]]\n",
    "\n",
    "topperformer = df.groupby(\"parameter_name\").mean().rename(columns={\"test_performance\": \"mean\"})\n",
    "b = df.groupby(\"parameter_name\").max()\n",
    "\n",
    "topperformer[\"max\"] = b\n",
    "topperformer.reset_index(inplace=True)\n",
    "\n",
    "topperformer.sort_values(\"mean\")\n",
    "\n",
    "display(topperformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code on how to evaluate specific models\n",
    "\n",
    "# local imports\n",
    "# model_file_name = \"-3841776332189409403step_0000.sd\"\n",
    "\n",
    "# Get the model parameters\n",
    "# candidates = masterframe[masterframe[\"model_file\"] == model_file_name]\n",
    "# assert candidates.shape[0] == 1, f\"1 != {candidates.shape}\"\n",
    "# candidate = candidates.iloc[0]\n",
    "\n",
    "# model_dir = os.path.join(EXPERIMENT_PATH, candidate[\"parameter_name\"])\n",
    "\n",
    "# Get the experiment file\n",
    "# files = next(os.walk(model_dir))[2]\n",
    "# files = [x for x in files if x.endswith(\".exp\")]\n",
    "# assert len(files) == 1, \"To many experiment files\"\n",
    "\n",
    "# Load experiment with good parameters\n",
    "# exp = load_savepoint(model_dir)\n",
    "# exp.load_agent_parameters(os.path.join(model_dir, model_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = load_datasets(VALIDATION_DATA_PATH)\n",
    "evaluation_function = lambda x,c: ev_function(dataset=x, context=c, modeltype=\"decision_tree\")\n",
    "tfds = lambda ds, fv, experiment: transform_dataset(\n",
    "    root_dataset = ds,\n",
    "    feature_values = fv,\n",
    "    evaluation_function = evaluation_function,\n",
    "    experiment = experiment,\n",
    "    predict = lambda agent, repre: agent(repre)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo\n",
    "if False:\n",
    "    overall = []\n",
    "    for vdata, context in validation_data:\n",
    "        res = [tfds(vdata, context) for _ in range(10)]\n",
    "        res = np.array(res)\n",
    "    \n",
    "        root_performance = evaluation_function(vdata,context, experiment)\n",
    "        overall.append(res.mean() - root_performance)\n",
    "        print(\n",
    "            \"| \",\n",
    "            vdata.name.rjust(20), \" | \",\n",
    "            f\"{root_performance:1.3f} | \",\n",
    "            f\"{res.mean():1.3f}+-{res.std():1.3f}\"\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_validation_performance(model_dir, model_file_name):\n",
    "    # Get the experiment file\n",
    "    files = next(os.walk(model_dir))[2]\n",
    "    files = [x for x in files if x.endswith(\".exp\")]\n",
    "    assert len(files) == 1, \"To many experiment files\"\n",
    "\n",
    "    # Load experiment with good parameters\n",
    "    exp = load_savepoint(model_dir)\n",
    "    \n",
    "    # Hack, can be removed later\n",
    "    exp.dir_path = model_dir\n",
    "    \n",
    "    exp.load_agent_parameters(os.path.join(model_dir, model_file_name))\n",
    "    \n",
    "    \n",
    "    overall = []\n",
    "    for vdata, context in validation_data:\n",
    "        res = []\n",
    "        for _ in range(5):\n",
    "            tmp = []\n",
    "            for _ in range(5):\n",
    "                try:\n",
    "                    tmp.append(tfds(vdata, context, exp))\n",
    "                except:\n",
    "                    print(\"ERROR\")\n",
    "                    traceback.print_exc()\n",
    "                    \n",
    "            assert len(tmp) > 0\n",
    "            res.append(max(tmp))\n",
    "        res = np.array(res)\n",
    "    \n",
    "        root_performance = evaluation_function(vdata,context)\n",
    "        overall.append(res.mean() - root_performance)\n",
    "    \n",
    "    overall = np.array(overall)\n",
    "    return overall.mean(), overall.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "experiment_a_table_1 = [\n",
    "    {\"reward_function\": \"binary_reward\", \"representation_generator\": \"random_sampling\", \"learning_algorithm\": \"REINFORCE\"},\n",
    "    {\"reward_function\": \"binary_reward\", \"representation_generator\": \"random_sampling\", \"learning_algorithm\": \"PPO\"},\n",
    "    {\"reward_function\": \"staggered_reward\", \"representation_generator\": \"random_sampling\", \"learning_algorithm\": \"REINFORCE\"},\n",
    "    {\"reward_function\": \"staggered_reward\", \"representation_generator\": \"random_sampling\", \"learning_algorithm\": \"PPO\"},\n",
    "    {\"reward_function\": \"binary_reward\", \"representation_generator\": \"quantile_data_sketch\", \"learning_algorithm\": \"REINFORCE\"},\n",
    "    {\"reward_function\": \"binary_reward\", \"representation_generator\": \"quantile_data_sketch\", \"learning_algorithm\": \"PPO\"},\n",
    "    {\"reward_function\": \"staggered_reward\", \"representation_generator\": \"quantile_data_sketch\", \"learning_algorithm\": \"REINFORCE\"},\n",
    "    {\"reward_function\": \"staggered_reward\", \"representation_generator\": \"quantile_data_sketch\", \"learning_algorithm\": \"PPO\"},    \n",
    "]\n",
    "\n",
    "experiment_a_table_2 = experiment_a_table_1.copy()\n",
    "\n",
    "experiment_b = [\n",
    "    {\"enable_local_context\": False, \"enable_domain_information\": False},\n",
    "    {\"enable_local_context\": True, \"enable_domain_information\": False},\n",
    "    {\"enable_local_context\": False, \"enable_domain_information\": True},\n",
    "    {\"enable_local_context\": True, \"enable_domain_information\": True},\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best(a):\n",
    "    \"\"\"\n",
    "        Select best model for a given set of parameters.\n",
    "    \"\"\"\n",
    "    selectors = []\n",
    "    for x in a:\n",
    "        selectors.append(masterframe[x] == a[x])\n",
    "    \n",
    "    if len(a) == 0:\n",
    "        selected = masterframe\n",
    "    else:\n",
    "        selector = selectors[0]\n",
    "        for s in selectors[1:]: selector = selector & s\n",
    "        selected = masterframe[selector]\n",
    "    \n",
    "    max_value = selected[\"test_performance\"].max()\n",
    "\n",
    "    chosen_model = selected[selected[\"test_performance\"] == max_value]\n",
    "    chosen_model = chosen_model.iloc[0,:]\n",
    "    return chosen_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latexify(s: str)-> str:\n",
    "    return s.replace(\"_\", \"\\\\_\")\n",
    "    \n",
    "def latex_table_row(lst) -> str:\n",
    "    s = \"\"\n",
    "    for i in lst:\n",
    "        s += f\"{latexify(i)} & \"\n",
    "        \n",
    "    # Cut off last &\n",
    "    s = s[:-2]\n",
    "    s += \"\\\\\\\\\"\n",
    "        \n",
    "    return s\n",
    "    \n",
    "def evaluate_model(params):\n",
    "    # Get best model with given parameters\n",
    "    best_model = select_best(params)\n",
    "    \n",
    "    # Load dir and filename\n",
    "    model_dir = best_model[\"model_path\"]\n",
    "    model_file_name = best_model[\"model_file\"]\n",
    "    \n",
    "    # Generate values\n",
    "    mean, std = get_mean_validation_performance(model_dir, model_file_name)\n",
    "        \n",
    "    c1 = best_model[\"reward_function\"]\n",
    "    c2 = best_model[\"representation_generator\"]\n",
    "    c3 = best_model[\"learning_algorithm\"]\n",
    "    return [ c1, c2, c3, f\"{mean:1.3f}$\\pm${std:1.3f}\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment A Tabelle 1\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    # Do stuff here\n",
    "\n",
    "    print(\"Experiment A Tabelle 1\")\n",
    "    for p in experiment_a_table_1:\n",
    "        #s = evaluate_model(p)\n",
    "        #s = latex_table_row(s)\n",
    "        #print(s)\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment A Tabelle 1\n",
      "{'enable_local_context': False, 'enable_domain_information': False}\n",
      "{'enable_local_context': True, 'enable_domain_information': False}\n",
      "{'enable_local_context': False, 'enable_domain_information': True}\n",
      "{'enable_local_context': True, 'enable_domain_information': True}\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    # Do stuff here\n",
    "\n",
    "    print(\"Experiment A Tabelle 1\")\n",
    "    for p in experiment_b:\n",
    "        #s = evaluate_model(p)\n",
    "        #s = latex_table_row(s)\n",
    "        print(p)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_dataset(model_dir, model_file_name, dataset, context, a=3, b=5):\n",
    "    # Get the experiment file\n",
    "    files = next(os.walk(model_dir))[2]\n",
    "    files = [x for x in files if x.endswith(\".exp\")]\n",
    "    assert len(files) == 1, \"To many experiment files\"\n",
    "\n",
    "    # Load experiment with good parameters\n",
    "    exp = load_savepoint(model_dir)\n",
    "    \n",
    "    # Hack, can be removed later\n",
    "    exp.dir_path = model_dir\n",
    "    \n",
    "    exp.load_agent_parameters(os.path.join(model_dir, model_file_name))\n",
    "    \n",
    "    \n",
    "    res = []\n",
    "    for _ in range(a):\n",
    "        tmp = []\n",
    "        for _ in range(b):\n",
    "            try:\n",
    "                tmp.append(tfds(dataset, context, exp))\n",
    "            except:\n",
    "                print(\"ERROR\")\n",
    "                traceback.print_exc()\n",
    "                \n",
    "        assert len(tmp) > 0\n",
    "        res.append(max(tmp))\n",
    "    res = np.array(res)\n",
    "    \n",
    "    root_performance = evaluation_function(dataset,context)\n",
    "    \n",
    "    print(dataset.name, res.mean(), res.std(), root_performance)\n",
    "    \n",
    "\n",
    "# Get best model\n",
    "best_model = select_best({})\n",
    "\n",
    "# Load dir and filename\n",
    "model_dir = best_model[\"model_path\"]\n",
    "model_file_name = best_model[\"model_file\"]\n",
    "\n",
    "data = load_datasets(DATA_PATH)\n",
    "relevant = []\n",
    "for ds in [x for x in data if x[0].name in relevant]:\n",
    "    get_mean_dataset(model_dir, model_file_name, ds[0], ds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model\n",
    "best_model = select_best({})\n",
    "\n",
    "# Load dir and filename\n",
    "model_dir = best_model[\"model_path\"]\n",
    "model_file_name = best_model[\"model_file\"]\n",
    "\n",
    "data = load_datasets(DATA_PATH)\n",
    "relevant = []\n",
    "for ds in [x for x in data if x[0].name in relevant]:\n",
    "    get_mean_dataset(model_dir, model_file_name, ds[0], ds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mushrooms', 'ionosphere', 'churn_modelling', 'baloons', 'fourclass', 'campus_recruit', 'glass', 'diabetes', 'lymphography', 'sklearn_boston', 'australian', 'credit_approval', 'pokemon', 'liver_disorders', 'world_happiness', 'svmguide1', 'splice', 'soybean', 'skin_nonskin', 'ges_classification', 'blood_transfusions', 'sklearn_cancer', 'accelerometer', 'balance_scale', 'ecoli', 'svmguide3', 'spect_heart', 'madelon', 'spambase', 'iris', 'fertility', 'sklearn_wine', 'default_credit']\n",
      "default_credit 0.7268999999999999 0.004799999999999971 0.7153\n"
     ]
    }
   ],
   "source": [
    "# Get best model\n",
    "best_model = select_best({})\n",
    "\n",
    "# Load dir and filename\n",
    "model_dir = best_model[\"model_path\"]\n",
    "model_file_name = best_model[\"model_file\"]\n",
    "\n",
    "data = load_datasets(DATA_PATH)\n",
    "\n",
    "print([x[0].name for x in data])\n",
    "\n",
    "relevant = [\"default_credit\"]\n",
    "for ds in [x for x in data if x[0].name in relevant]:\n",
    "    get_mean_dataset(model_dir, model_file_name, ds[0], ds[1], a=2, b=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes 0.7152777777777777 0.0026755269110108684 0.6979166666666666\n",
      "ecoli 0.8329014227642277 0.003633218914145104 0.8258384146341463\n"
     ]
    }
   ],
   "source": [
    "# Get best model\n",
    "best_model = select_best({})\n",
    "\n",
    "# Load dir and filename\n",
    "model_dir = best_model[\"model_path\"]\n",
    "model_file_name = best_model[\"model_file\"]\n",
    "\n",
    "data = load_datasets(DATA_PATH)\n",
    "relevant = [\"diabetes\", \"ecoli\"]\n",
    "for ds in [x for x in data if x[0].name in relevant]:\n",
    "    get_mean_dataset(model_dir, model_file_name, ds[0], ds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model\n",
    "best_model = select_best({})\n",
    "\n",
    "# Load dir and filename\n",
    "model_dir = best_model[\"model_path\"]\n",
    "model_file_name = best_model[\"model_file\"]\n",
    "\n",
    "data = load_datasets(DATA_PATH)\n",
    "relevant = [\"sklearn_digits\"]\n",
    "for ds in [x for x in data if x[0].name in relevant]:\n",
    "    get_mean_dataset(model_dir, model_file_name, ds[0], ds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
